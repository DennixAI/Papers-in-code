{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa54830b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.49.2)\n",
      "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.10.0+cu128)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (26.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2025.3.0)\n",
      "Requirement already satisfied: cuda-bindings==12.9.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.9.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.4.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.6.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.6.0)\n",
      "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings==12.9.4->torch<3,>=2.3->bitsandbytes) (1.3.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n",
      "Connected to Hugging Face Repo: FusionCorp/gemma-zero\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import HfApi, create_repo\n",
    "from huggingface_hub import hf_hub_download\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from torch.amp import autocast, GradScaler\n",
    "import torch.utils.checkpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "!pip install bitsandbytes\n",
    "import bitsandbytes as bnb\n",
    "try:\n",
    "    import datasets\n",
    "    import transformers\n",
    "except ImportError:\n",
    "    print(\"Installing dependencies...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call([\"pip\", \"install\", \"-q\", \"datasets\", \"transformers\", \"accelerate\"])\n",
    "    from datasets import load_dataset, concatenate_datasets\n",
    "    from transformers import AutoTokenizer\n",
    "else:\n",
    "    from datasets import load_dataset, concatenate_datasets\n",
    "    from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "#load_dotenv()\n",
    "HF_TOKEN = \"\"\n",
    "REPO_NAME = \"FusionCorp/gemma-zero\"\n",
    "\n",
    "if not HF_TOKEN or not REPO_NAME:\n",
    "    raise ValueError(\"Error: HF_TOKEN or REPO_NAME not found in .env file.\")\n",
    "\n",
    "\n",
    "api = HfApi(token=HF_TOKEN)\n",
    "try:\n",
    "    create_repo(repo_id=REPO_NAME, repo_type=\"model\", token=HF_TOKEN, exist_ok=True)\n",
    "    print(f\"Connected to Hugging Face Repo: {REPO_NAME}\")\n",
    "except Exception as e:\n",
    "    print(f\" Repo Connection Failed: {e}\")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GemmaZeroConfig:\n",
    "    vocab_size: int = 50257      # Must be 50257 for GPT2\n",
    "    hidden_size: int = 768    \n",
    "    intermediate_size: int = 3072\n",
    "    num_hidden_layers: int = 6\n",
    "    num_attention_heads: int = 6\n",
    "    num_key_value_heads: int = 2\n",
    "    head_dim: int = 128\n",
    "    max_position_embeddings: int = 1024\n",
    "    rms_norm_eps: float = 1e-6\n",
    "    rope_theta: float = 10000.0\n",
    "    attn_logit_softcapping: float = 50.0\n",
    "    final_logit_softcapping: float = 30.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31ffef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GemmaRMSNorm(nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "    def forward(self, x):\n",
    "        x_float = x.float()\n",
    "        variance = x_float.pow(2).mean(-1, keepdim=True)\n",
    "        x_float = x_float * torch.rsqrt(variance + self.eps)\n",
    "        return (x_float * self.weight.float()).type_as(x) + 1.0\n",
    "\n",
    "class GemmaRotaryEmbedding(nn.Module):\n",
    "    def __init__(self, dim, max_position_embeddings=2048, base=10000, device=None):\n",
    "        super().__init__()\n",
    "        inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2).float().to(device) / dim))\n",
    "        self.register_buffer(\"inv_freq\", inv_freq, persistent=False)\n",
    "    def forward(self, x, seq_len=None):\n",
    "        t = torch.arange(seq_len, device=x.device, dtype=self.inv_freq.dtype)\n",
    "        freqs = torch.einsum(\"i,j->ij\", t, self.inv_freq)\n",
    "        emb = torch.cat((freqs, freqs), dim=-1)\n",
    "        return emb.cos(), emb.sin()\n",
    "\n",
    "def apply_rotary_pos_emb(q, k, cos, sin):\n",
    "    def rotate_half(x): return torch.cat((-x[..., x.shape[-1] // 2:], x[..., :x.shape[-1] // 2]), dim=-1)\n",
    "    return (q * cos) + (rotate_half(q) * sin), (k * cos) + (rotate_half(k) * sin)\n",
    "\n",
    "class GemmaAttention(nn.Module):\n",
    "    def __init__(self, config: GemmaZeroConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.num_heads = config.num_attention_heads\n",
    "        self.head_dim = config.head_dim\n",
    "        self.num_key_value_heads = config.num_key_value_heads\n",
    "        self.num_key_value_groups = self.num_heads // self.num_key_value_heads\n",
    "        self.hidden_size = config.hidden_size\n",
    "        \n",
    "        self.q_proj = nn.Linear(config.hidden_size, self.num_heads * self.head_dim, bias=False)\n",
    "        self.k_proj = nn.Linear(config.hidden_size, self.num_key_value_heads * self.head_dim, bias=False)\n",
    "        self.v_proj = nn.Linear(config.hidden_size, self.num_key_value_heads * self.head_dim, bias=False)\n",
    "        self.o_proj = nn.Linear(self.num_heads * self.head_dim, config.hidden_size, bias=False)\n",
    "        self.rotary_emb = GemmaRotaryEmbedding(self.head_dim, config.max_position_embeddings, config.rope_theta)\n",
    "\n",
    "        # GEMMA 3: QK-Norm (RMSNorm on Queries and Keys)\n",
    "        # This stabilizes training and allows us to use Flash Attention\n",
    "        self.q_norm = GemmaRMSNorm(self.head_dim, eps=config.rms_norm_eps)\n",
    "        self.k_norm = GemmaRMSNorm(self.head_dim, eps=config.rms_norm_eps)\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask=None):\n",
    "        bsz, q_len, _ = hidden_states.size()\n",
    "        \n",
    "        # 1. Projections\n",
    "        q = self.q_proj(hidden_states).view(bsz, q_len, self.num_heads, self.head_dim)\n",
    "        k = self.k_proj(hidden_states).view(bsz, q_len, self.num_key_value_heads, self.head_dim)\n",
    "        v = self.v_proj(hidden_states).view(bsz, q_len, self.num_key_value_heads, self.head_dim)\n",
    "\n",
    "        # 2. QK Norm (Gemma 3 feature)\n",
    "        q = self.q_norm(q)\n",
    "        k = self.k_norm(k)\n",
    "\n",
    "        # 3. RoPE\n",
    "        # Transpose for RoPE: (bsz, heads, seq, dim)\n",
    "        q = q.transpose(1, 2)\n",
    "        k = k.transpose(1, 2)\n",
    "        v = v.transpose(1, 2)\n",
    "        \n",
    "        cos, sin = self.rotary_emb(v, seq_len=q_len)\n",
    "        q, k = apply_rotary_pos_emb(q, k, cos, sin)\n",
    "\n",
    "        # 4. GQA Expansion\n",
    "        # (Expand K and V to match Q heads for calculation)\n",
    "        k = k.repeat_interleave(self.num_key_value_groups, dim=1)\n",
    "        v = v.repeat_interleave(self.num_key_value_groups, dim=1)\n",
    "\n",
    "        # 5. Flash Attention (Much faster, less memory)\n",
    "        # We drop manual soft-capping here to enable Flash Attention. \n",
    "        # QK-Norm handles the stability role of soft-capping.\n",
    "        attn_output = F.scaled_dot_product_attention(\n",
    "            q, k, v, \n",
    "            attn_mask=None, # Flash attn handles causal mask internally if is_causal=True\n",
    "            dropout_p=0.0, \n",
    "            is_causal=True\n",
    "        )\n",
    "\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().view(bsz, q_len, -1)\n",
    "        return self.o_proj(attn_output)\n",
    "\n",
    "class GemmaBlock(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.input_layernorm = GemmaRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n",
    "        self.self_attn = GemmaAttention(config)\n",
    "        self.post_attention_layernorm = GemmaRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(config.hidden_size, config.intermediate_size, bias=False), \n",
    "            nn.Linear(config.hidden_size, config.intermediate_size, bias=False), \n",
    "            nn.Linear(config.intermediate_size, config.hidden_size, bias=False) \n",
    "        )\n",
    "        self.mlp_gate = self.mlp[0]; self.mlp_up = self.mlp[1]; self.mlp_down = self.mlp[2]\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        r = x; x = self.input_layernorm(x); x = self.self_attn(x, attention_mask=mask); x = r + x\n",
    "        r = x; x = self.post_attention_layernorm(x)\n",
    "        gate, val = self.mlp_gate(x), self.mlp_up(x)\n",
    "        x = self.mlp_down(F.gelu(gate) * val)\n",
    "        return r + x\n",
    "\n",
    "class GemmaZeroModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.embed_tokens = nn.Embedding(config.vocab_size, config.hidden_size)\n",
    "        self.layers = nn.ModuleList([GemmaBlock(config) for _ in range(config.num_hidden_layers)])\n",
    "        self.norm = GemmaRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n",
    "        self.embed_scale = math.sqrt(config.hidden_size)\n",
    "        self.gradient_checkpointing = False\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "\n",
    "    def gradient_checkpointing_enable(self): self.gradient_checkpointing = True\n",
    "\n",
    "\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        x = self.embed_tokens(input_ids) * self.embed_scale\n",
    "        for layer in self.layers:\n",
    "            if self.gradient_checkpointing and self.training:\n",
    "                # This line saves ~10GB of VRAM by re-calculating \n",
    "                # activations during the backward pass.\n",
    "                x = torch.utils.checkpoint.checkpoint(\n",
    "                    layer, \n",
    "                    x, \n",
    "                    None,\n",
    "                    use_reentrant=False\n",
    "                )\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        x = self.norm(x)\n",
    "        logits = torch.matmul(x, self.embed_tokens.weight.t())\n",
    "        if self.config.final_logit_softcapping:\n",
    "             logits = torch.tanh(logits / self.config.final_logit_softcapping) * self.config.final_logit_softcapping\n",
    "             \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3caef68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "\n",
    "class TinyStoriesDataset(IterableDataset):\n",
    "    def __init__(self, seq_len=2048):\n",
    "        self.seq_len = seq_len\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        # Load dataset\n",
    "        self.dataset = load_dataset(\"roneneldan/TinyStories\", split=\"train\", streaming=True)\n",
    "\n",
    "    def __iter__(self):\n",
    "        iterator = iter(self.dataset)\n",
    "        for item in iterator:\n",
    "            if len(item['text']) < 50: continue\n",
    "            \n",
    "            # Simple truncation/padding\n",
    "            tokens = self.tokenizer(\n",
    "                item['text'], \n",
    "                max_length=self.seq_len, \n",
    "                truncation=True, \n",
    "                padding=\"max_length\",\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            yield tokens.input_ids.squeeze(0)\n",
    "\n",
    "def get_tinystories_loader(batch_size=4, seq_len=2048):\n",
    "    ds = TinyStoriesDataset(seq_len=seq_len)\n",
    "    # num_workers=2 runs tokenization in parallel background processes\n",
    "    return DataLoader(ds, batch_size=batch_size, num_workers=2, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b2ac87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Checking Hugging Face for a resume checkpoint...\n",
      "â„¹ï¸ No remote checkpoint found or couldn't access it. Starting fresh. (404 Client Error. (Request ID: Root=1-699b7f06-1037182c40846fa64bff8d7c;557125ec-3605-4c10-ba73-ce01ecb347e9)\n",
      "\n",
      "Entry Not Found for url: https://huggingface.co/FusionCorp/gemma-zero/resolve/main/latest_full_checkpoint.pth.)\n",
      "ðŸ†• No checkpoint found. Starting training from Step 0.\n",
      "ðŸš€ Training in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0222 22:11:38.971000 976 torch/_inductor/utils.py:1679] [1/0] Not enough SMs to use max_autotune_gemm mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100 | Loss: 6.9677\n",
      "Step 200 | Loss: 4.9176\n",
      "Step 300 | Loss: 4.2129\n",
      "Step 400 | Loss: 4.6030\n",
      "Step 500 | Loss: 3.4684\n",
      "Step 600 | Loss: 3.4300\n",
      "Step 700 | Loss: 3.6780\n",
      "Step 800 | Loss: 3.4635\n",
      "Step 900 | Loss: 3.2960\n",
      "Step 1000 | Loss: 2.5788\n",
      "ðŸ’¾ Step 1000: Saving and Uploading...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bf94c0ece214dc5b04136a577af610c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf3209ff1fe4340a89794652cbf5437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aa205ebcf0847bfac7d81e746211e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  pytorch_model.bin           :   0%|          |  561kB /  362MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "544bdf8a215b48d3b8fbbeb605f1b053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "559edf76944948b3b51346f3622d310e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8f3edab375a439d8c0edfff59dda901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  full_checkpoint.pth         :   6%|6         | 33.4MB /  546MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Step 1000 uploaded to HF.\n",
      "Step 1100 | Loss: 3.1897\n",
      "Step 1200 | Loss: 2.6044\n",
      "Step 1300 | Loss: 2.5564\n",
      "Step 1400 | Loss: 2.6462\n",
      "Step 1500 | Loss: 2.9488\n",
      "Step 1600 | Loss: 2.4998\n",
      "Step 1700 | Loss: 2.7284\n",
      "Step 1800 | Loss: 2.6141\n",
      "Step 1900 | Loss: 2.2095\n",
      "Step 2000 | Loss: 3.1535\n",
      "ðŸ’¾ Step 2000: Saving and Uploading...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b110d37cafa2432ea8f6da3f497cd231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10f48bffcc34ce38d4195965d3bed00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "044df1dfcb1b486f9fc8c3c7eb4987f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  pytorch_model.bin           :   0%|          |  563kB /  362MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f78f5baaf68245dfad2ac44ed01083a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa78b92d52d24bd79838aa5dbdb305e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac1752c3456482e901a11923a38f864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  full_checkpoint.pth         :   6%|6         | 33.3MB /  546MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Step 2000 uploaded to HF.\n",
      "Step 2100 | Loss: 2.6268\n",
      "Step 2200 | Loss: 2.4046\n",
      "Step 2300 | Loss: 2.2112\n",
      "Step 2400 | Loss: 2.0923\n",
      "Step 2500 | Loss: 2.2230\n",
      "Step 2600 | Loss: 2.2922\n",
      "Step 2700 | Loss: 2.5619\n",
      "Step 2800 | Loss: 2.5845\n",
      "Step 2900 | Loss: 2.0535\n",
      "Step 3000 | Loss: 2.6359\n",
      "ðŸ’¾ Step 3000: Saving and Uploading...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d274db2b0a14ca1a8e3885762d9fb40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f2150eaebf44181b737c86712d40625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d71360d49fa400ebab9291d6ae2fbdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  pytorch_model.bin           :   0%|          |  565kB /  362MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d0b3f50825c4bea8db8a5c24cc27423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ba1cc3373184777b64fdb9256cb1778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8682594f80b84af6b60de8f0dde8589e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  full_checkpoint.pth         :   6%|6         | 33.1MB /  546MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Step 3000 uploaded to HF.\n",
      "Step 3100 | Loss: 2.6942\n",
      "Step 3200 | Loss: 2.2045\n",
      "Step 3300 | Loss: 2.4812\n",
      "Step 3400 | Loss: 2.4862\n",
      "Step 3500 | Loss: 2.6251\n",
      "Step 3600 | Loss: 2.5435\n",
      "Step 3700 | Loss: 2.1929\n",
      "Step 3800 | Loss: 2.5110\n",
      "Step 3900 | Loss: 2.6978\n",
      "Step 4000 | Loss: 2.4257\n",
      "ðŸ’¾ Step 4000: Saving and Uploading...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bda644f4b5f420ea1b0fe9898483e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5896772dd5434636ac0e1ee4f32cdb28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c3abf5f2f314b0c9efe03b5d4cf25bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  pytorch_model.bin           :   0%|          |  566kB /  362MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcc29b61427d4817b47d4f82a7bb2d67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "122d0e6370f94459b22038652bf061af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4186bf4b93d4212aff51fe64e320f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  full_checkpoint.pth         :   6%|6         | 33.3MB /  546MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Step 4000 uploaded to HF.\n",
      "Step 4100 | Loss: 1.8063\n",
      "Step 4200 | Loss: 1.9036\n",
      "Step 4300 | Loss: 2.2040\n",
      "Step 4400 | Loss: 2.6712\n",
      "Step 4500 | Loss: 2.4857\n",
      "Step 4600 | Loss: 2.1930\n",
      "Step 4700 | Loss: 2.4536\n",
      "Step 4800 | Loss: 1.9190\n",
      "Step 4900 | Loss: 2.1195\n",
      "Step 5000 | Loss: 2.6012\n",
      "ðŸ’¾ Step 5000: Saving and Uploading...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cbbaf36cf3e4bf884aa7417336ed30f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ea8dc035b942df9ce3b0a47b13b04a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eed607331a44765bb6a9d3ab7a4a8e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  pytorch_model.bin           :   0%|          |  568kB /  362MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fb0e66de3a647a1b8d3a37e8e8411ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17e3f41145e3481f8acd11b1bd31ebfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2729c7f48e534ae8b4b2d65cc307d79b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  full_checkpoint.pth         :   6%|6         | 33.4MB /  546MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Step 5000 uploaded to HF.\n",
      "Step 5100 | Loss: 2.2867\n",
      "Step 5200 | Loss: 1.8993\n",
      "Step 5300 | Loss: 2.2413\n",
      "Step 5400 | Loss: 2.3847\n",
      "Step 5500 | Loss: 1.7511\n",
      "Step 5600 | Loss: 2.2695\n",
      "Step 5700 | Loss: 1.8840\n",
      "Step 5800 | Loss: 2.2204\n",
      "Step 5900 | Loss: 2.3943\n",
      "Step 6000 | Loss: 2.4704\n",
      "ðŸ’¾ Step 6000: Saving and Uploading...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbf7bebff4b1426fbc4097c00f0fb458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de232a58784c493280041a3546620937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f27d50c74746f19dc7d88deb2eda24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  pytorch_model.bin           :   0%|          |  569kB /  362MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cf04fd51e044c8db4691086828b37d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bf0d8f6737946c79a500ba24c77abb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fffe993b94984641bc28d41a8df6ffce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  full_checkpoint.pth         :   6%|6         | 33.3MB /  546MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Step 6000 uploaded to HF.\n",
      "Step 6100 | Loss: 2.4362\n",
      "Step 6200 | Loss: 1.6443\n",
      "Step 6300 | Loss: 2.1639\n",
      "Step 6400 | Loss: 2.2446\n",
      "Step 6500 | Loss: 1.9549\n",
      "Step 6600 | Loss: 1.7276\n",
      "Step 6700 | Loss: 2.3454\n",
      "Step 6800 | Loss: 1.8718\n",
      "Step 6900 | Loss: 1.9560\n",
      "Step 7000 | Loss: 2.1586\n",
      "ðŸ’¾ Step 7000: Saving and Uploading...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33aca71937394f1fb76b0f6282e10d1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0556c6a8d7b4fb2a991594fb2f65f7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc218a0e5cbe46e0b7e2ef7d3ecd3167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  pytorch_model.bin           :   0%|          |  569kB /  362MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eecaca592a1444d7bf94ca58f6bfd8c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9c5fffdb46f4d91937a67ec200a91f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b2fc4334e8f49ddbe6bf62122045f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  full_checkpoint.pth         :   6%|6         | 33.4MB /  546MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Step 7000 uploaded to HF.\n",
      "Step 7100 | Loss: 2.1354\n",
      "Step 7200 | Loss: 1.7044\n",
      "Step 7300 | Loss: 1.8135\n",
      "Step 7400 | Loss: 1.6869\n",
      "Step 7500 | Loss: 1.8702\n",
      "Step 7600 | Loss: 2.3859\n",
      "Step 7700 | Loss: 1.5482\n",
      "Step 7800 | Loss: 1.7438\n",
      "Step 7900 | Loss: 2.0387\n",
      "Step 8000 | Loss: 2.0623\n",
      "ðŸ’¾ Step 8000: Saving and Uploading...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "475ab585330244f8840a14ba73554486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "024dceef8a2d4df584d69a81c04acbb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9cee514323048d69f332421267a152a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  pytorch_model.bin           :   0%|          |  570kB /  362MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d395a854232349c3b90a9ebc635aee8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3d143f6b71245bd9e282c97e854eb6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea75d06a806e4a97a3c0daba8d7d073f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  full_checkpoint.pth         :   6%|6         | 33.4MB /  546MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Step 8000 uploaded to HF.\n",
      "Step 8100 | Loss: 2.0530\n",
      "Step 8200 | Loss: 2.0987\n",
      "Step 8300 | Loss: 1.9588\n",
      "Step 8400 | Loss: 1.7525\n",
      "Step 8500 | Loss: 1.8295\n",
      "Step 8600 | Loss: 1.7004\n",
      "Step 8700 | Loss: 2.3398\n",
      "Step 8800 | Loss: 1.8813\n",
      "Step 8900 | Loss: 1.6742\n",
      "Step 9000 | Loss: 1.6293\n",
      "ðŸ’¾ Step 9000: Saving and Uploading...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20589bc9f6014da1ab5d3403300f086c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cbe7a1e3677464d84fac0709d397eb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "010cc67380b2405298630a2bdec53c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  pytorch_model.bin           :   0%|          |  570kB /  362MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "935da69b89bd408cabd974fbcb4442d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63cb4266e90640a3a15cc719c2f64dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5192016e737c4030868e921b186825f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  full_checkpoint.pth         :   6%|6         | 32.9MB /  546MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Step 9000 uploaded to HF.\n",
      "Step 9100 | Loss: 2.0705\n",
      "Step 9200 | Loss: 1.7915\n",
      "Step 9300 | Loss: 2.3404\n",
      "Step 9400 | Loss: 2.0607\n",
      "Step 9500 | Loss: 2.2220\n",
      "Step 9600 | Loss: 2.0287\n",
      "Step 9700 | Loss: 2.0881\n",
      "Step 9800 | Loss: 2.2674\n",
      "Step 9900 | Loss: 2.1109\n",
      "Step 10000 | Loss: 2.2097\n",
      "ðŸ’¾ Step 10000: Saving and Uploading...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec4c227ccf64bfbb5af078e831b1474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df65cfa8586d4a628078bffb6868532a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e7b314c23b144218ee9d5ee3d0555e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  pytorch_model.bin           :   0%|          |  571kB /  362MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e86ae8a74f1a4614bd152dbd32ebd061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e608f712363d42a89b3f555abb27597f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a322938f6c024a8b81a41dceec6e8da4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  full_checkpoint.pth         :   6%|6         | 33.4MB /  546MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Step 10000 uploaded to HF.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def train():\n",
    "    device = \"cuda\"\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    config = GemmaZeroConfig()\n",
    "    model = GemmaZeroModel(config).to(device)\n",
    "    model.gradient_checkpointing_enable()\n",
    "    \n",
    "    FULL_CHECKPOINT_NAME = \"full_checkpoint.pth\"\n",
    "    LIGHT_WEIGHTS_NAME = \"pytorch_model.bin\"\n",
    "    LOSS_FILE = \"loss.txt\"\n",
    "\n",
    "    optimizer = bnb.optim.AdamW8bit(model.parameters(), lr=6e-4, weight_decay=0.01)\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    BATCH_SIZE = 8    \n",
    "    ACCUM_STEPS = 4     \n",
    "    SEQ_LEN = 1024       \n",
    "    TOTAL_STEPS = 20000  \n",
    "    \n",
    "    scheduler = get_cosine_schedule_with_warmup(optimizer, 100, TOTAL_STEPS // ACCUM_STEPS)\n",
    "    \n",
    "    start_step = 0\n",
    "    loss_history = []\n",
    "    val_loss_history = []\n",
    "    val_ppl_history = []\n",
    "    val_steps = []\n",
    "    \n",
    "    if not os.path.exists(FULL_CHECKPOINT_NAME) and HF_TOKEN and HF_TOKEN != \"hf_...\":\n",
    "        try:\n",
    "            checkpoint_path = hf_hub_download(repo_id=REPO_NAME, filename=\"latest_full_checkpoint.pth\", token=HF_TOKEN)\n",
    "            import shutil\n",
    "            shutil.copy(checkpoint_path, FULL_CHECKPOINT_NAME)\n",
    "        except: pass\n",
    "\n",
    "    if os.path.exists(FULL_CHECKPOINT_NAME):\n",
    "        checkpoint = torch.load(FULL_CHECKPOINT_NAME, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
    "        start_step = checkpoint['step'] + 1\n",
    "        loss_history = checkpoint.get('loss_history', [])\n",
    "        val_loss_history = checkpoint.get('val_loss_history', [])\n",
    "        val_ppl_history = checkpoint.get('val_ppl_history', [])\n",
    "        val_steps = checkpoint.get('val_steps', [])\n",
    "        print(f\"âœ… Resumed at Step {start_step}\")\n",
    "\n",
    "    try: model = torch.compile(model)\n",
    "    except: pass\n",
    "\n",
    "    train_loader = DataLoader(TinyStoriesDataset(SEQ_LEN), batch_size=BATCH_SIZE)\n",
    "    val_ds = load_dataset(\"roneneldan/TinyStories\", split=\"validation\", streaming=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    data_iter = iter(train_loader)\n",
    "    pad_token_id = 50256\n",
    "    model.train()\n",
    "\n",
    "    for step in range(start_step, TOTAL_STEPS):\n",
    "        try: inputs = next(data_iter).to(device)\n",
    "        except StopIteration: data_iter = iter(train_loader); inputs = next(data_iter).to(device)\n",
    "        \n",
    "        labels = inputs.clone()\n",
    "        labels[labels == pad_token_id] = -100\n",
    "\n",
    "        with autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "            logits = model(inputs)\n",
    "            loss = F.cross_entropy(logits[..., :-1, :].contiguous().view(-1, config.vocab_size), labels[..., 1:].contiguous().view(-1), ignore_index=-100)\n",
    "            loss = loss / ACCUM_STEPS\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        actual_loss = loss.item() * ACCUM_STEPS\n",
    "        loss_history.append(actual_loss)\n",
    "        \n",
    "        if (step + 1) % ACCUM_STEPS == 0:\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            # Validation and Plotting\n",
    "            if (step + 1) % 500 == 0:\n",
    "                model.eval()\n",
    "                v_losses = []\n",
    "                v_iter = iter(val_loader)\n",
    "                for _ in range(10): # Run 10 batches for validation\n",
    "                    try: \n",
    "                        v_in = next(v_iter).to(device)\n",
    "                        v_lab = v_in.clone()\n",
    "                        v_lab[v_lab == pad_token_id] = -100\n",
    "                        with torch.no_grad(), autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "                            v_logits = model(v_in)\n",
    "                            v_loss = F.cross_entropy(v_logits[..., :-1, :].contiguous().view(-1, config.vocab_size), v_lab[..., 1:].contiguous().view(-1), ignore_index=-100)\n",
    "                            v_losses.append(v_loss.item())\n",
    "                    except StopIteration: break\n",
    "                \n",
    "                avg_v_loss = sum(v_losses)/len(v_losses)\n",
    "                val_loss_history.append(avg_v_loss)\n",
    "                val_ppl_history.append(math.exp(avg_v_loss))\n",
    "                val_steps.append(step + 1)\n",
    "                model.train()\n",
    "\n",
    "                clear_output(wait=True)\n",
    "                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "                ax1.plot(loss_history, color='blue', alpha=0.2, label='Train Loss')\n",
    "                if len(loss_history) > 50:\n",
    "                    ma = [sum(loss_history[i-50:i])/50 for i in range(50, len(loss_history))]\n",
    "                    ax1.plot(range(50, len(loss_history)), ma, color='blue', label='Train Trend')\n",
    "                ax1.plot(val_steps, val_loss_history, 'o-', color='red', label='Val Loss')\n",
    "                ax1.set_title(f\"Loss | Step {step+1}: {actual_loss:.4f}\")\n",
    "                ax1.legend(); ax1.grid(True, alpha=0.3)\n",
    "\n",
    "                ax2.plot(val_steps, val_ppl_history, 'o-', color='green', label='Val Perplexity')\n",
    "                ax2.set_title(f\"Perplexity: {val_ppl_history[-1]:.2f}\")\n",
    "                ax2.set_yscale('log'); ax2.legend(); ax2.grid(True, alpha=0.3)\n",
    "                plt.show()\n",
    "\n",
    "        if (step + 1) % 1000 == 0 and HF_TOKEN and HF_TOKEN != \"hf_...\":\n",
    "            with open(LOSS_FILE, \"w\") as f:\n",
    "                for l in loss_history: f.write(f\"{l}\\n\")\n",
    "\n",
    "            torch.save(model.state_dict(), LIGHT_WEIGHTS_NAME)\n",
    "            full_checkpoint = {\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'scaler_state_dict': scaler.state_dict(),\n",
    "                'step': step,\n",
    "                'loss_history': loss_history,\n",
    "                'val_loss_history': val_loss_history,\n",
    "                'val_ppl_history': val_ppl_history,\n",
    "                'val_steps': val_steps\n",
    "            }\n",
    "            torch.save(full_checkpoint, FULL_CHECKPOINT_NAME)\n",
    "            try:\n",
    "                api.upload_file(path_or_fileobj=LIGHT_WEIGHTS_NAME, path_in_repo=f\"checkpoint-{step+1}/pytorch_model.bin\", repo_id=REPO_NAME)\n",
    "                api.upload_file(path_or_fileobj=FULL_CHECKPOINT_NAME, path_in_repo=\"latest_full_checkpoint.pth\", repo_id=REPO_NAME)\n",
    "                api.upload_file(path_or_fileobj=LOSS_FILE, path_in_repo=\"loss_history.txt\", repo_id=REPO_NAME)\n",
    "            except Exception as e: print(f\"âŒ Upload Failed: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0df515c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: The old businessman was very angry when his computer\n",
      "Generating...\n",
      "\n",
      "Final Story:\n",
      "The old businessman was very angry when his computer was in the living room. She was very angry and she wanted to make the computer better. She asked her mom if she could help him. Her mom said yes, and she gave the computer a big hug.\n",
      "\n",
      "The computer was so happy! It was so big and bright. The computer was so big and bright. The computer was so big and bright. The computer was so big and bright.\n",
      "\n",
      "The computer was so happy to be alive. She hugged the computer and thanked it\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 1. Load the tokenizer and your EXACT model architecture\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "config = GemmaZeroConfig()\n",
    "# Make sure to set num_key_value_heads to whatever you changed it to!\n",
    "model = GemmaZeroModel(config).to(\"cuda\")\n",
    "\n",
    "# 2. Download the saved weights\n",
    "from huggingface_hub import hf_hub_download\n",
    "weights_path = hf_hub_download(repo_id=\"FusionCorp/gemma-zero\", filename=\"checkpoint-10000/pytorch_model.bin\")\n",
    "\n",
    "# Load the raw dictionary\n",
    "state_dict = torch.load(weights_path, map_location=\"cuda\")\n",
    "\n",
    "# --- THE FIX: Remove the \"_orig_mod.\" prefix from the keys ---\n",
    "clean_state_dict = {}\n",
    "for key, value in state_dict.items():\n",
    "    clean_key = key.replace(\"_orig_mod.\", \"\")\n",
    "    clean_state_dict[clean_key] = value\n",
    "\n",
    "# Load the cleaned dictionary into your model\n",
    "model.load_state_dict(clean_state_dict)\n",
    "model.eval()\n",
    "\n",
    "# 3. Write a prompt and generate!\n",
    "prompt = \"The old businessman was very angry when his computer\"\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print(\"Generating...\")\n",
    "\n",
    "with torch.no_grad(), torch.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "    for _ in range(100): # Generate 50 words\n",
    "        logits = model(input_ids)\n",
    "        next_token_logits = logits[:, -1, :]\n",
    "        \n",
    "        # Pick the most likely next word\n",
    "        next_token = torch.argmax(next_token_logits, dim=-1).unsqueeze(0)\n",
    "        input_ids = torch.cat([input_ids, next_token], dim=-1)\n",
    "        \n",
    "        if next_token.item() == tokenizer.eos_token_id:\n",
    "            break\n",
    "\n",
    "print(\"\\nFinal Story:\")\n",
    "print(tokenizer.decode(input_ids[0].cpu().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72b31356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation dataset...\n",
      "Calculating loss over 100 unseen batches...\n",
      "\n",
      "âœ… VALIDATION COMPLETE\n",
      "ðŸ“Š Average Val Loss: 1.8160\n",
      "ðŸ“ˆ Val Perplexity: 6.1470\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from huggingface_hub import hf_hub_download\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1. SETUP & LOAD MODEL\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "config = GemmaZeroConfig() # Uses your class from the previous cells\n",
    "model = GemmaZeroModel(config).to(device)\n",
    "\n",
    "# 2. DOWNLOAD & CLEAN WEIGHTS (Handling the _orig_mod prefix)\n",
    "weights_path = hf_hub_download(repo_id=\"FusionCorp/gemma-zero\", filename=\"checkpoint-10000/pytorch_model.bin\")\n",
    "state_dict = torch.load(weights_path, map_location=device)\n",
    "clean_dict = {k.replace(\"_orig_mod.\", \"\"): v for k, v in state_dict.items()}\n",
    "model.load_state_dict(clean_dict)\n",
    "model.eval()\n",
    "\n",
    "# 3. PREPARE VALIDATION DATA (The \"Validation\" split)\n",
    "print(\"Loading validation dataset...\")\n",
    "val_ds = load_dataset(\"roneneldan/TinyStories\", split=\"validation\", streaming=True)\n",
    "\n",
    "def val_collate(batch):\n",
    "    texts = [item['text'] for item in batch]\n",
    "    tokens = tokenizer(texts, max_length=1024, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    return tokens.input_ids.to(device)\n",
    "\n",
    "# We'll check 100 batches to get a very accurate average\n",
    "val_loader = DataLoader(val_ds, batch_size=8, collate_fn=val_collate)\n",
    "val_iter = iter(val_loader)\n",
    "\n",
    "# 4. RUN VALIDATION LOOP\n",
    "val_loss = 0\n",
    "num_batches = 100 \n",
    "\n",
    "print(f\"Calculating loss over {num_batches} unseen batches...\")\n",
    "with torch.no_grad(), torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "    for i in range(num_batches):\n",
    "        inputs = next(val_iter)\n",
    "        labels = inputs.clone()\n",
    "        labels[labels == tokenizer.eos_token_id] = -100 # Ignore padding in loss\n",
    "        \n",
    "        logits = model(inputs)\n",
    "        \n",
    "        # Flatten for CrossEntropy\n",
    "        shift_logits = logits[..., :-1, :].contiguous()\n",
    "        shift_labels = labels[..., 1:].contiguous()\n",
    "        \n",
    "        loss = F.cross_entropy(shift_logits.view(-1, config.vocab_size), shift_labels.view(-1), ignore_index=-100)\n",
    "        val_loss += loss.item()\n",
    "\n",
    "avg_val_loss = val_loss / num_batches\n",
    "print(f\"\\nâœ… VALIDATION COMPLETE\")\n",
    "print(f\"ðŸ“Š Average Val Loss: {avg_val_loss:.4f}\")\n",
    "print(f\"ðŸ“ˆ Val Perplexity: {torch.exp(torch.tensor(avg_val_loss)).item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7864a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395db0c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
